{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using XGBoost to work with dataset that includes missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Master_Clean_w_NaN.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>Age</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>Irregular_Pulse</th>\n",
       "      <th>Systolic_BP_Avg</th>\n",
       "      <th>Diastolic_BP_Avg</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Height_cm</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Waist_cm</th>\n",
       "      <th>...</th>\n",
       "      <th>Family_Income_15.0</th>\n",
       "      <th>Family_Income_nan</th>\n",
       "      <th>Gender_1.0</th>\n",
       "      <th>Gender_2.0</th>\n",
       "      <th>Race_1.0</th>\n",
       "      <th>Race_2.0</th>\n",
       "      <th>Race_3.0</th>\n",
       "      <th>Race_4.0</th>\n",
       "      <th>Race_6.0</th>\n",
       "      <th>Race_7.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83732.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.666667</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>94.8</td>\n",
       "      <td>184.5</td>\n",
       "      <td>27.8</td>\n",
       "      <td>101.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83733.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>90.4</td>\n",
       "      <td>171.4</td>\n",
       "      <td>30.8</td>\n",
       "      <td>107.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83735.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>109.8</td>\n",
       "      <td>160.9</td>\n",
       "      <td>42.4</td>\n",
       "      <td>110.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83736.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>55.2</td>\n",
       "      <td>164.9</td>\n",
       "      <td>20.3</td>\n",
       "      <td>80.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83741.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.333333</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>76.6</td>\n",
       "      <td>165.4</td>\n",
       "      <td>28.0</td>\n",
       "      <td>86.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEQN   Age  Heart_Rate  Irregular_Pulse  Systolic_BP_Avg  \\\n",
       "0  83732.0  62.0        76.0              0.0       122.666667   \n",
       "1  83733.0  53.0        72.0              0.0       140.000000   \n",
       "2  83735.0  56.0        78.0              0.0       134.000000   \n",
       "3  83736.0  42.0        76.0              0.0       104.000000   \n",
       "4  83741.0  22.0        66.0              0.0       111.333333   \n",
       "\n",
       "   Diastolic_BP_Avg  Weight_kg  Height_cm   BMI  Waist_cm    ...     \\\n",
       "0         65.333333       94.8      184.5  27.8     101.1    ...      \n",
       "1         86.000000       90.4      171.4  30.8     107.9    ...      \n",
       "2         70.000000      109.8      160.9  42.4     110.1    ...      \n",
       "3         60.000000       55.2      164.9  20.3      80.4    ...      \n",
       "4         72.666667       76.6      165.4  28.0      86.6    ...      \n",
       "\n",
       "   Family_Income_15.0  Family_Income_nan  Gender_1.0  Gender_2.0  Race_1.0  \\\n",
       "0                   0                  0           1           0         0   \n",
       "1                   0                  0           1           0         0   \n",
       "2                   0                  0           0           1         0   \n",
       "3                   0                  0           0           1         0   \n",
       "4                   0                  0           1           0         0   \n",
       "\n",
       "   Race_2.0  Race_3.0  Race_4.0  Race_6.0  Race_7.0  \n",
       "0         0         1         0         0         0  \n",
       "1         0         1         0         0         0  \n",
       "2         0         1         0         0         0  \n",
       "3         0         0         1         0         0  \n",
       "4         0         0         1         0         0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4707, 68)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[np.isfinite(df['Target'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4423, 68)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4423,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df.drop(columns=['SEQN', 'Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4423, 66)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3473"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 98.73%\n",
      "Validation accuracy: 98.31%\n"
     ]
    }
   ],
   "source": [
    "training_preds = clf.predict(X_train)\n",
    "val_preds = clf.predict(X_test)\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.9830508474576272\n",
      "F1 Score:        0.0\n",
      "Precision Score: 0.0\n",
      "Recall Score:    0.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99       870\n",
      "         1.0       0.00      0.00      0.00        15\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       885\n",
      "   macro avg       0.49      0.50      0.50       885\n",
      "weighted avg       0.97      0.98      0.97       885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score:  ' + str(accuracy_score(y_test, val_preds)))\n",
    "print('F1 Score:        ' + str(f1_score(y_test, val_preds)))\n",
    "print('Precision Score: ' + str(precision_score(y_test, val_preds)))\n",
    "print('Recall Score:    ' + str(recall_score(y_test, val_preds)) )\n",
    "report = classification_report(y_test, val_preds)\n",
    "print ('')\n",
    "print (report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [6],\n",
    "    'min_child_weight': [10],\n",
    "    'subsample': [ 0.7],\n",
    "    'n_estimators': [5, 30, 100, 250],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search found the following optimal parameters: \n",
      "learning_rate: 0.1\n",
      "max_depth: 6\n",
      "min_child_weight: 10\n",
      "n_estimators: 250\n",
      "subsample: 0.7\n",
      "\n",
      "Training Accuracy: 99.89%\n",
      "Validation accuracy: 97.29%\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(scale_pos_weight=53)\n",
    "grid_clf = GridSearchCV(clf, param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "\n",
    "best_parameters = grid_clf.best_params_\n",
    "\n",
    "print(\"Grid Search found the following optimal parameters: \")\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "training_preds = grid_clf.predict(X_train)\n",
    "val_preds = grid_clf.predict(X_test)\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9392312 , 0.96212549, 0.96919163, 0.97427925])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth' : [3, 5, 6, 7],\n",
    "    'learning_rate' : [0.1],\n",
    "    'n_estimators' : [5, 30, 80, 100],\n",
    "    'silent' : [True],\n",
    "    'objective' : ['binary:logistic'],\n",
    "    'booster' : ['gbtree'],\n",
    "    'n_jobs' : [1],\n",
    "    'nthread' : [None],\n",
    "    'gamma' : [0],\n",
    "    'min_child_weight' : [1, 5, 10],\n",
    "    'max_delta_step' : [0],\n",
    "    'subsample' : [1, 0.7],\n",
    "    'colsample_bytree' : [1],\n",
    "    'colsample_bylevel' : [1],\n",
    "    'reg_alpha' : [0],\n",
    "    'reg_lambda' : [1],\n",
    "    'scale_pos_weight' : [53],\n",
    "    'base_score' : [0.5],\n",
    "    'random_state' : [0],\n",
    "    'seed' : [None],\n",
    "    'missing' : [None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search found the following optimal parameters: \n",
      "base_score: 0.5\n",
      "booster: 'gbtree'\n",
      "colsample_bylevel: 1\n",
      "colsample_bytree: 1\n",
      "gamma: 0\n",
      "learning_rate: 0.1\n",
      "max_delta_step: 0\n",
      "max_depth: 3\n",
      "min_child_weight: 10\n",
      "missing: None\n",
      "n_estimators: 80\n",
      "n_jobs: 1\n",
      "nthread: None\n",
      "objective: 'binary:logistic'\n",
      "random_state: 0\n",
      "reg_alpha: 0\n",
      "reg_lambda: 1\n",
      "scale_pos_weight: 53\n",
      "seed: None\n",
      "silent: True\n",
      "subsample: 0.7\n",
      "\n",
      "Training Accuracy: 95.03%\n",
      "Validation accuracy: 93.11%\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier()\n",
    "grid_clf = GridSearchCV(clf, param_grid, scoring='roc_auc', cv=None, n_jobs=1)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "\n",
    "best_parameters = grid_clf.best_params_\n",
    "\n",
    "print(\"Grid Search found the following optimal parameters: \")\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "training_preds = grid_clf.predict(X_train)\n",
    "val_preds = grid_clf.predict(X_test)\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.9310734463276836\n",
      "F1 Score:        0.18666666666666668\n",
      "Precision Score: 0.11666666666666667\n",
      "Recall Score:    0.4666666666666667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.94      0.96       870\n",
      "         1.0       0.12      0.47      0.19        15\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       885\n",
      "   macro avg       0.55      0.70      0.58       885\n",
      "weighted avg       0.98      0.93      0.95       885\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(predictions, probs, train_predictions, train_probs):\n",
    "    \"\"\"Compare machine learning model to baseline performance.\n",
    "    Computes statistics and shows ROC curve.\"\"\"\n",
    "    \n",
    "    baseline = {}\n",
    "    \n",
    "    baseline['recall'] = recall_score(y_test, [0 for _ in range(len(y_test))])\n",
    "    baseline['precision'] = precision_score(y_test, [0 for _ in range(len(y_test))])\n",
    "    baseline['roc'] = 0.5\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['recall'] = recall_score(y_test, predictions)\n",
    "    results['precision'] = precision_score(y_test, predictions)\n",
    "    results['roc'] = roc_auc_score(y_test, probs)\n",
    "    \n",
    "    train_results = {}\n",
    "    train_results['recall'] = recall_score(y_train, train_predictions)\n",
    "    train_results['precision'] = precision_score(y_train, train_predictions)\n",
    "    train_results['roc'] = roc_auc_score(y_train, train_probs)\n",
    "    \n",
    "    for metric in ['recall', 'precision', 'roc']:\n",
    "        print(f'{metric.capitalize()} Baseline: {round(baseline[metric], 2)} Test: {round(results[metric], 2)} Train: {round(train_results[metric], 2)}')\n",
    "    \n",
    "    # Calculate false positive rates and true positive rates\n",
    "    base_fpr, base_tpr, _ = roc_curve(y_test, [0 for _ in range(len(y_test))])\n",
    "    model_fpr, model_tpr, _ = roc_curve(y_test, probs)\n",
    "\n",
    "    plt.figure(figsize = (8, 6))\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    \n",
    "    # Plot both curves\n",
    "    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n",
    "    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n",
    "    plt.legend();\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curves');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xgb_predictions = best_model.predict(X_train)\n",
    "train_xgb_probs = best_model.predict_proba(X_train)[:,1]\n",
    "\n",
    "xgb_predictions = best_model.predict(X_test)\n",
    "xgb_probs = best_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
